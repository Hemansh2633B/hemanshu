<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AI Computer Vision Suite - Full Features</title>
<style>
  /* Reset and base styling */
  *, *::before, *::after {
    box-sizing: border-box;
  }
  body {
    margin: 0; 
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    background: #121212;
    color: #e0e0e0;
    height: 100vh;
    display: flex;
    flex-direction: row;
    overflow: hidden;
  }
  nav {
    width: 280px;
    background-color: #1e1e2f;
    display: flex;
    flex-direction: column;
    padding: 1rem 0;
    border-right: 2px solid #3c3c5a;
  }
  nav h1 {
    color: #61dafb;
    font-weight: 700;
    text-align: center;
    margin-bottom: 1.5rem;
    user-select: none;
  }
  nav button {
    background: none;
    border: none;
    color: #a8b2d1;
    padding: 1rem 2rem;
    font-size: 1.1rem;
    text-align: left;
    cursor: pointer;
    border-left: 4px solid transparent;
    transition: background-color 0.3s, border-color 0.3s;
    user-select: none;
  }
  nav button:hover, nav button.active {
    background-color: #25253f;
    color: #61dafb;
    border-left-color: #61dafb;
  }
  main {
    flex-grow: 1;
    background-color: #181824;
    overflow-y: auto;
    padding: 1.5rem 2rem;
    display: flex;
    flex-direction: column;
  }
  section {
    display: none;
    flex-direction: column;
  }
  section.active {
    display: flex;
  }
  h2 {
    margin-top: 0;
    margin-bottom: 0.5rem;
    color: #61dafb;
  }
  p.description {
    color: #9099b7;
    margin-top: 0;
    margin-bottom: 1rem;
  }
  button, input[type=file] {
    border: none;
    outline: none;
    background-color: #303050;
    color: #c7c7c7;
    font-weight: 600;
    padding: 0.6rem 1.2rem;
    border-radius: 6px;
    cursor: pointer;
    transition: background-color 0.3s;
    margin-top: 1rem;
  }
  button:disabled {
    background-color: #444666;
    cursor: not-allowed;
    color: #8888aa;
  }
  button:hover:not(:disabled), input[type=file]:hover {
    background-color: #61dafb;
    color: #121212;
  }
  input[type=file] {
    padding: 0.4rem 0.8rem;
  }
  .canvas-container {
    position: relative;
    max-width: 720px;
    margin-top: 1rem;
    border-radius: 12px;
    overflow: hidden;
    box-shadow:
      0 0 8px #61dafbaa,
      0 0 12px #61dafb66 inset;
  }
  canvas, video, img {
    width: 100%;
    border-radius: 12px;
    display: block;
  }
  /* Absolute bounding boxes */
  .bounding-box {
    position: absolute;
    border: 2px solid #61dafb;
    box-sizing: border-box;
    border-radius: 3px;
    pointer-events: none;
  }
  .label {
    position: absolute;
    background-color: #61dafb;
    color: #121212;
    font-weight: 700;
    padding: 0 5px;
    font-size: 0.8rem;
    user-select: none;
    border-radius: 3px 3px 3px 3px;
    white-space: nowrap;
  }
  /* Scrollable saved results */
  .saved-results {
    max-height: 260px;
    margin-top: 1rem;
    overflow-y: auto;
    background: #23233e;
    border-radius: 10px;
    padding: 0.75rem;
  }
  .saved-item {
    display: flex;
    gap: 1rem;
    margin-bottom: 0.8rem;
    border-bottom: 1px solid #3c3c5a;
    padding-bottom: 0.5rem;
    align-items: center;
  }
  .saved-item img {
    width: 120px;
    border-radius: 8px;
    box-shadow: 0 0 6px #61dafbaa;
  }
  .saved-desc {
    color: #9aa0b7;
    font-size: 0.9rem;
    max-width: 500px;
    overflow-wrap: break-word;
  }
  ul.classify-list {
    list-style: none;
    padding-left: 0;
    color: #9aa0b7;
  }
  ul.classify-list li {
    margin-bottom: 0.3rem;
  }
  pre#ocr-result {
    background-color: #252543;
    color: #61dafb;
    padding: 1rem;
    border-radius: 10px;
    max-width: 720px;
    white-space: pre-wrap;
    margin-top: 1rem;
    max-height: 260px;
    overflow-y: auto;
    font-family: 'Segoe UI Mono', Consolas, monospace;
  }
  footer {
    text-align: center;
    margin-top: auto;
    color: #474a6e;
    font-size: 0.8rem;
    user-select: none;
    padding: 1rem 0;
  }
  /* Responsive */
  @media (max-width: 900px) {
    body {
      flex-direction: column;
      height: auto;
    }
    nav {
      width: 100%;
      border-right: none;
      border-bottom: 2px solid #3c3c5a;
      flex-direction: row;
      overflow-x: auto;
    }
    nav button {
      flex: 1 0 auto;
      padding: 0.75rem 1rem;
      font-size: 1rem;
      text-align: center;
    }
    main {
      padding: 1rem;
      height: auto;
    }
    .canvas-container {
      max-width: 100vw;
      border-radius: 0;
      box-shadow:none;
    }
  }
  /* Info tooltip for dataset */
  #imagenet-info {
    display: inline-block;
    border-bottom: 1px dotted #61dafb;
    cursor: help;
    position: relative;
  }
  #imagenet-info:hover::after {
    content: attr(data-tooltip);
    position: absolute;
    left: 0;
    bottom: 120%;
    background: #222644cc;
    color: #61dafb;
    padding: 6px 10px;
    border-radius: 6px;
    font-size: 0.9rem;
    white-space: nowrap;
  }
</style>
</head>
<body>
<nav>
  <h1>AI Vision Suite</h1>
  <button class="nav-btn active" data-target="live">Live Object Detection</button>
  <button class="nav-btn" data-target="upload">Image Upload Detection</button>
  <button class="nav-btn" data-target="classify">Image Classification</button>
  <button class="nav-btn" data-target="face">Live Face Detection</button>
  <button class="nav-btn" data-target="ocr">OCR Text Detection</button>
  <button class="nav-btn" data-target="segmentation">Image Segmentation</button>
</nav>
<main>
  <section id="live" class="active" role="tabpanel" aria-labelledby="liveTab">
    <h2>Live Object Detection</h2>
    <p class="description">Use your device camera to detect objects in real-time using COCO-SSD model.</p>
    <div>
      <button id="startLiveBtn">Start Camera</button>
      <button id="stopLiveBtn" disabled>Stop Camera</button>
    </div>
    <div class="canvas-container" style="margin-top:1rem; max-width:720px; position:relative;">
      <video id="liveVideo" autoplay muted playsinline style="background:#000;"></video>
      <canvas id="liveCanvas" style="position:absolute; top:0; left:0;"></canvas>
    </div>
  </section>

  <section id="upload" role="tabpanel" aria-labelledby="uploadTab">
    <h2>Upload Image for Detection</h2>
    <p class="description">Upload an image to detect objects with bounding boxes.</p>
    <input type="file" id="uploadInput" accept="image/*" />
    <button id="detectUploadBtn" disabled>Detect Objects</button>
    <button id="saveResultBtn" disabled>Save Result</button>
    <div class="canvas-container" style="margin-top:1rem; max-width:720px; position:relative;">
      <img id="uploadedImage" alt="Uploaded preview" />
      <canvas id="uploadCanvas" style="position:absolute; top:0; left:0;"></canvas>
    </div>
    <h3>Saved Results</h3>
    <div class="saved-results" id="savedResults"></div>
  </section>

  <section id="classify" role="tabpanel" aria-labelledby="classifyTab">
    <h2>Image Classification <span id="imagenet-info" data-tooltip="MobileNet is pretrained on the ImageNet dataset containing 1,000 object categories.">[?]</span></h2>
    <p class="description">Upload an image to classify it using MobileNet model pretrained on ImageNet dataset.</p>
    <input type="file" id="classifyInput" accept="image/*" />
    <button id="classifyBtn" disabled>Classify</button>
    <div style="margin-top:1rem; max-width:720px;">
      <img id="classifyImage" alt="Classification preview" />
    </div>
    <ul class="classify-list" id="classifyResults"></ul>
  </section>

  <section id="face" role="tabpanel" aria-labelledby="faceTab">
    <h2>Live Face Detection</h2>
    <p class="description">Live face detection using BlazeFace model.</p>
    <button id="startFaceBtn">Start Camera</button>
    <button id="stopFaceBtn" disabled>Stop Camera</button>
    <div class="canvas-container" style="margin-top:1rem; max-width:720px; position:relative;">
      <video id="faceVideo" autoplay muted playsinline style="background:#000;"></video>
      <canvas id="faceCanvas" style="position:absolute; top:0; left:0;"></canvas>
    </div>
  </section>

  <section id="ocr" role="tabpanel" aria-labelledby="ocrTab">
    <h2>OCR Text Recognition</h2>
    <p class="description">Upload an image to detect and extract text using Tesseract.js.</p>
    <input type="file" id="ocrInput" accept="image/*" />
    <button id="ocrBtn" disabled>Detect Text</button>
    <div style="margin-top:1rem; max-width:720px;">
      <img id="ocrImage" alt="OCR preview" />
    </div>
    <pre id="ocrResult"></pre>
  </section>

  <section id="segmentation" role="tabpanel" aria-labelledby="segmentationTab">
    <h2>Image Segmentation</h2>
    <p class="description">Upload an image to get semantic segmentation overlay using DeepLab model.</p>
    <input type="file" id="segmentInput" accept="image/*" />
    <button id="segmentBtn" disabled>Segment Image</button>
    <div class="canvas-container" style="margin-top:1rem; max-width:720px; position:relative;">
      <img id="segmentImage" alt="Segmentation preview" />
      <canvas id="segmentCanvas" style="position:absolute; top:0; left:0;"></canvas>
    </div>
  </section>

  <footer>
    &copy; 2024 AI Computer Vision Suite â€” Powered by TensorFlow.js and Friends
  </footer>
</main>

<!-- TensorFlow.js and Models -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.7.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/deeplab"></script>
<script src="https://cdn.jsdelivr.net/npm/tesseract.js@2.1.4/dist/tesseract.min.js"></script>

<script>
  // Navigation
  const navButtons = document.querySelectorAll('nav button.nav-btn');
  const sections = document.querySelectorAll('main section');

  navButtons.forEach(btn => {
    btn.addEventListener('click', () => {
      navButtons.forEach(b => b.classList.remove('active'));
      sections.forEach(s => s.classList.remove('active'));
      btn.classList.add('active');
      document.getElementById(btn.dataset.target).classList.add('active');
    });
  });

  // Helper: Clear bounding boxes
  function clearBoundingBoxes(container) {
    const boxes = container.querySelectorAll('.bounding-box');
    boxes.forEach(b => b.remove());
  }

  // -------- Live Object Detection --------
  const liveVideo = document.getElementById('liveVideo');
  const liveCanvas = document.getElementById('liveCanvas');
  const startLiveBtn = document.getElementById('startLiveBtn');
  const stopLiveBtn = document.getElementById('stopLiveBtn');
  const liveCtx = liveCanvas.getContext('2d');
  let liveStream = null;
  let liveModel = null;
  let liveAnimationId = null;

  async function loadCocoModel() {
    if (!liveModel) {
      liveModel = await cocoSsd.load();
      console.log('COCO-SSD Model Loaded.');
    }
  }

  function resizeLiveCanvas() {
    liveCanvas.width = liveVideo.videoWidth;
    liveCanvas.height = liveVideo.videoHeight;
    liveCanvas.style.width = liveVideo.offsetWidth + 'px';
    liveCanvas.style.height = liveVideo.offsetHeight + 'px';
  }

  async function detectLive() {
    if (!liveModel) return;
    if (liveVideo.readyState === 4) {
      resizeLiveCanvas();
      liveCtx.clearRect(0, 0, liveCanvas.width, liveCanvas.height);
      const predictions = await liveModel.detect(liveVideo);
      predictions.forEach(pred => {
        const [x, y, width, height] = pred.bbox;
        liveCtx.strokeStyle = '#61dafb';
        liveCtx.lineWidth = 3;
        liveCtx.font = '20px Segoe UI';
        liveCtx.fillStyle = '#61dafb';
        liveCtx.beginPath();
        liveCtx.rect(x, y, width, height);
        liveCtx.stroke();
        liveCtx.fillText(`${pred.class} ${(pred.score*100).toFixed(1)}%`, x, y > 20 ? y-6 : y+20);
      });
    }
    liveAnimationId = requestAnimationFrame(detectLive);
  }

  async function startLiveCamera() {
    try {
      liveStream = await navigator.mediaDevices.getUserMedia({video: {facingMode: 'environment'}, audio: false});
      liveVideo.srcObject = liveStream;
      await liveVideo.play();
      await loadCocoModel();
      detectLive();
      startLiveBtn.disabled = true;
      stopLiveBtn.disabled = false;
    } catch(e) {
      alert('Camera error: '+e.message);
    }
  }

  function stopLiveCamera() {
    if (liveStream) {
      liveStream.getTracks().forEach(track => track.stop());
    }
    if (liveAnimationId) {
      cancelAnimationFrame(liveAnimationId);
    }
    liveVideo.pause();
    liveVideo.srcObject = null;
    liveCtx.clearRect(0, 0, liveCanvas.width, liveCanvas.height);
    startLiveBtn.disabled = false;
    stopLiveBtn.disabled = true;
  }

  startLiveBtn.onclick = startLiveCamera;
  stopLiveBtn.onclick = stopLiveCamera;

  // -------- Upload Image Object Detection --------
  const uploadInput = document.getElementById('uploadInput');
  const detectUploadBtn = document.getElementById('detectUploadBtn');
  const saveResultBtn = document.getElementById('saveResultBtn');
  const uploadedImage = document.getElementById('uploadedImage');
  const uploadCanvas = document.getElementById('uploadCanvas');
  const uploadCtx = uploadCanvas.getContext('2d');
  let uploadModel = null;
  let currentUploadPredictions = null;
  let currentUploadImage = null;

  uploadInput.onchange = (e) => {
    const file = e.target.files[0];
    if (!file) return;
    const url = URL.createObjectURL(file);
    uploadedImage.src = url;
    uploadedImage.style.display = 'block';
    uploadedImage.onload = () => {
      uploadCanvas.width = uploadedImage.naturalWidth;
      uploadCanvas.height = uploadedImage.naturalHeight;
      uploadCanvas.style.width = uploadedImage.width + 'px';
      uploadCanvas.style.height = uploadedImage.height + 'px';
      uploadCtx.clearRect(0,0,uploadCanvas.width, uploadCanvas.height);
      detectUploadBtn.disabled = false;
      saveResultBtn.disabled = true;
      currentUploadPredictions = null;
      currentUploadImage = uploadedImage.src;
      clearBoundingBoxes(uploadCanvas.parentElement);
    };
  };

  async function loadUploadModel() {
    if (!uploadModel) {
      uploadModel = await cocoSsd.load();
      console.log('COCO-SSD Model loaded for upload.');
    }
  }

  async function detectUpload() {
    if (!uploadModel) await loadUploadModel();
    const predictions = await uploadModel.detect(uploadedImage);
    uploadCtx.clearRect(0, 0, uploadCanvas.width, uploadCanvas.height);
    clearBoundingBoxes(uploadCanvas.parentElement);
    uploadCtx.lineWidth = 3;
    uploadCtx.strokeStyle = '#61dafb';
    uploadCtx.font = '20px Segoe UI';
    uploadCtx.fillStyle = '#61dafb';
    predictions.forEach(pred => {
      const [x, y, width, height] = pred.bbox;
      uploadCtx.beginPath();
      uploadCtx.rect(x, y, width, height);
      uploadCtx.stroke();
      uploadCtx.fillText(`${pred.class} ${(pred.score*100).toFixed(1)}%`, x, y > 20 ? y-6 : y+20);
    });
    currentUploadPredictions = predictions;
    saveResultBtn.disabled = false;
  }
  detectUploadBtn.onclick = detectUpload;

  // Save detection results in localStorage
  const savedResultsContainer = document.getElementById('savedResults');
  saveResultBtn.onclick = () => {
    if (!currentUploadPredictions || !currentUploadImage) return;
    const storedResults = JSON.parse(localStorage.getItem('savedDetectionResults') || '[]');
    storedResults.push({
      id: Date.now(),
      image: currentUploadImage,
      predictions: currentUploadPredictions
    });
    localStorage.setItem('savedDetectionResults', JSON.stringify(storedResults));
    alert('Detection result saved locally.');
    saveResultBtn.disabled = true;
    loadSavedResults();
  };

  function loadSavedResults() {
    savedResultsContainer.innerHTML = '';
    const stored = JSON.parse(localStorage.getItem('savedDetectionResults') || '[]');
    if (!stored.length) {
      savedResultsContainer.textContent = 'No saved detection results.';
      return;
    }
    stored.forEach(item => {
      const div = document.createElement('div');
      div.className = 'saved-item';
      const img = document.createElement('img');
      img.src = item.image;
      img.alt = 'Saved detection';
      div.appendChild(img);
      const desc = document.createElement('div');
      desc.className = 'saved-desc';
      desc.textContent = `Detected ${item.predictions.length} object(s): ` + item.predictions.map(p => p.class).join(', ');
      div.appendChild(desc);
      savedResultsContainer.appendChild(div);
    });
  }
  loadSavedResults();

  // -------- Image Classification --------
  const classifyInput = document.getElementById('classifyInput');
  const classifyBtn = document.getElementById('classifyBtn');
  const classifyImage = document.getElementById('classifyImage');
  const classifyResults = document.getElementById('classifyResults');
  let classifyModel = null;

  classifyInput.onchange = e => {
    const file = e.target.files[0];
    if (!file) return;
    const url = URL.createObjectURL(file);
    classifyImage.src = url;
    classifyImage.style.display = 'block';
    classifyResults.innerHTML = '';
    classifyBtn.disabled = false;
  };

  async function loadClassifyModel() {
    if (!classifyModel) {
      classifyModel = await mobilenet.load();
      console.log('MobileNet model loaded');
    }
  }

  async function classify() {
    if (!classifyModel) await loadClassifyModel();
    classifyResults.innerHTML = '<li>Classifying...</li>';
    const predictions = await classifyModel.classify(classifyImage);
    classifyResults.innerHTML = '';
    predictions.forEach(p => {
      const li = document.createElement('li');
      li.textContent = `${p.className}: ${(p.probability*100).toFixed(2)}%`;
      classifyResults.appendChild(li);
    });
  }
  classifyBtn.onclick = classify;

  // -------- Live Face Detection --------
  const faceVideo = document.getElementById('faceVideo');
  const faceCanvas = document.getElementById('faceCanvas');
  const faceCtx = faceCanvas.getContext('2d');
  const startFaceBtn = document.getElementById('startFaceBtn');
  const stopFaceBtn = document.getElementById('stopFaceBtn');
  let faceStream = null;
  let faceModel = null;
  let faceAnimationId = null;

  async function loadFaceModel() {
    if (!faceModel) {
      faceModel = await blazeface.load();
      console.log('BlazeFace model loaded');
    }
  }

  function resizeFaceCanvas() {
    faceCanvas.width = faceVideo.videoWidth;
    faceCanvas.height = faceVideo.videoHeight;
    faceCanvas.style.width = faceVideo.offsetWidth + 'px';
    faceCanvas.style.height = faceVideo.offsetHeight + 'px';
  }

  async function detectFaces() {
    if (!faceModel) return;
    if (faceVideo.readyState === 4) {
      resizeFaceCanvas();
      faceCtx.clearRect(0, 0, faceCanvas.width, faceCanvas.height);
      const predictions = await faceModel.estimateFaces(faceVideo, false);
      if (predictions.length > 0) {
        faceCtx.lineWidth = 3;
        faceCtx.strokeStyle = '#61dafb';
        faceCtx.font = '20px Segoe UI';
        faceCtx.fillStyle = '#61dafb';
        predictions.forEach(pred => {
          const start = pred.topLeft;
          const end = pred.bottomRight;
          const size = [end[0] - start[0], end[1] - start[1]];
          faceCtx.beginPath();
          faceCtx.rect(start[0], start[1], size[0], size[1]);
          faceCtx.stroke();
          faceCtx.fillText('Face', start[0], start[1] > 20 ? start[1] - 6 : start[1] + 20);
        });
      }
    }
    faceAnimationId = requestAnimationFrame(detectFaces);
  }

  async function startFaceCamera() {
    try {
      faceStream = await navigator.mediaDevices.getUserMedia({video: { facingMode: "user" }, audio: false});
      faceVideo.srcObject = faceStream;
      await faceVideo.play();
      await loadFaceModel();
      detectFaces();
      startFaceBtn.disabled = true;
      stopFaceBtn.disabled = false;
    } catch (e) {
      alert('Error accessing camera: ' + e.message);
    }
  }

  function stopFaceCamera() {
    if (faceStream) {
      faceStream.getTracks().forEach(t => t.stop());
    }
    faceVideo.pause();
    faceVideo.srcObject = null;
    if (faceAnimationId) {
      cancelAnimationFrame(faceAnimationId);
    }
    faceCtx.clearRect(0, 0, faceCanvas.width, faceCanvas.height);
    startFaceBtn.disabled = false;
    stopFaceBtn.disabled = true;
  }

  startFaceBtn.onclick = startFaceCamera;
  stopFaceBtn.onclick = stopFaceCamera;

  // -------- OCR Text Recognition --------
  const ocrInput = document.getElementById('ocrInput');
  const ocrBtn = document.getElementById('ocrBtn');
  const ocrImage = document.getElementById('ocrImage');
  const ocrResult = document.getElementById('ocrResult');
  let ocrWorker = null;

  ocrInput.onchange = e => {
    const file = e.target.files[0];
    if (!file) return;
    const url = URL.createObjectURL(file);
    ocrImage.src = url;
    ocrImage.style.display = 'block';
    ocrResult.textContent = '';
    ocrBtn.disabled = false;
  };

  async function initOCR() {
    if (!ocrWorker) {
      ocrWorker = Tesseract.createWorker({
        logger: m => {
          if (m.status === 'recognizing text') {
            ocrResult.textContent = `Recognizing... ${(m.progress * 100).toFixed(1)}%`;
          }
        }
      });
      await ocrWorker.load();
      await ocrWorker.loadLanguage('eng');
      await ocrWorker.initialize('eng');
    }
  }

  async function runOCR() {
    await initOCR();
    const { data: { text }} = await ocrWorker.recognize(ocrImage);
    ocrResult.textContent = text || '(No text recognized)';
  }

  ocrBtn.onclick = runOCR;

  // -------- Image Segmentation --------
  const segmentInput = document.getElementById('segmentInput');
  const segmentBtn = document.getElementById('segmentBtn');
  const segmentImage = document.getElementById('segmentImage');
  const segmentCanvas = document.getElementById('segmentCanvas');
  const segmentCtx = segmentCanvas.getContext('2d');
  let segmentModel = null;

  segmentInput.onchange = e => {
    const file = e.target.files[0];
    if (!file) return;
    const url = URL.createObjectURL(file);
    segmentImage.src = url;
    segmentImage.style.display = 'block';
    segmentCanvas.width = 0;
    segmentCanvas.height = 0;
    segmentCtx.clearRect(0, 0, segmentCanvas.width, segmentCanvas.height);
    segmentBtn.disabled = false;
  };

  async function loadSegmentModel() {
    if (!segmentModel) {
      segmentModel = await deeplab.load({base: 'pascal'});
      console.log('DeepLab model loaded');
    }
  }

  async function segment() {
    if (!segmentModel) await loadSegmentModel();
    segmentCanvas.width = segmentImage.naturalWidth;
    segmentCanvas.height = segmentImage.naturalHeight;
    segmentCanvas.style.width = segmentImage.width + 'px';
    segmentCanvas.style.height = segmentImage.height + 'px';

    const segmentation = await segmentModel.segment(segmentImage);

    // Prepare mask overlay on canvas
    const { legend, height, width, segmentationMap } = segmentation;
    const imageData = segmentCtx.createImageData(width, height);
    
    for (let i = 0; i < width * height; i++) {
      const segmentId = segmentationMap[i];
      if (segmentId === -1) {
        imageData.data[4 * i + 3] = 0; // fully transparent pixels outside segments
        continue;
      }
      const color = legend[segmentId]?.color || [0, 0, 0];
      imageData.data[4 * i] = color[0];     // red
      imageData.data[4 * i + 1] = color[1]; // green
      imageData.data[4 * i + 2] = color[2]; // blue
      imageData.data[4 * i + 3] = 150;      // semi-transparent alpha
    }

    segmentCtx.clearRect(0, 0, width, height);
    segmentCtx.drawImage(segmentImage, 0, 0, width, height);
    segmentCtx.putImageData(imageData, 0, 0);
  }

  segmentBtn.onclick = segment;

</script>
</body>
</html>

